{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_AIDA 2021-2022.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Βοηθητικό υλικό για την εργασία στο μάθημα AIDA \n",
        "\n",
        "******\n",
        "Δεν είναι απαραίτητο να χρησιμοποιήσετε τον κώδικα ή τις τεχνικές που παρουσιάζονται στο παρών notebook. Το υλικό αυτό δίνεται ως βοήθημα και μπορεί να χρησιμοποιηθεί ως έχει ή να το προσαρμόσετε όπως νομίζετε ή να μην το χρησιμοποιήσετε καθόλου στην δική σας υλοποίηση.\n",
        "\n",
        "Ο κώδικας αποτελεί μέρος του project που βρίσκεται σε [αυτό](https://github.com/geofila/Conceptual-Edits-as-Counterfactual-Explanations) το αποθετήριο.\n",
        "******\n",
        "## Κατασκευή του Dataset\n",
        "\n",
        "\n",
        "1. Αρχικά πρέπει να κατεβάσουμε το dataset από το site και στην συνέχεια να το αποσυμπιέσουμε ώστε να χρησιμοποιήσουμε το json αρχείο που περιέχει πληροφορίες σχετικά με τις εικόνες.\n",
        "2. Στην συνέχεια θα διαβάσουμε τις πληροφορίες που περιέχονται στο το json.\n",
        "3. Θα φιλτράρουμε τις εικόνες με βάση τα αντικείμενα που θέλουμε να περιέχουν για να ολοκληρώσουμε την κατασκευή του Dataset. Για αυτό παρέχετε ένα αντικείμενο με το όνομα COCO το όποιο δέχεται στην είσοδο τα δεδομένα από το json αρχείο. Η κλάση αυτή διατηρεί τις πληροφορίες της σε ένα dictonary με το όνομα coco, το όποιο περιέχει πληροφορίες αρχικά για όλες τις εικόνες. Επίσης έχει μια μέθοδο prune_dataset η όποια δέχεται στην είσοδο μια λίστα από strings με τα ονόματα των αντικειμένων τα όποια θέλουμε να περιέχονται στις εικόνες. Η μέθοδος αυτή κλαδεύει τις εικόνες από το dictionary του cocο. Οι τελικές εικόνες που θα έχει το dictonary coco θα είναι οι εικόνες που περιέχουν όλα τα αντικείμενα που δόθηκαν στην λίστα (ή και περισσότερα). Οπότε αν η μέθοδος κληθεί με ορίσματα `[cat, dog]` τότε μείνουν μόνο οι εικόνες που περιέχουν σίγουρα και cat και dog και μπορεί και παραπάνω αντικείμενα π.χ. book."
      ],
      "metadata": {
        "id": "72FOphZwN7f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip # download dataset\n",
        "!unzip annotations_trainval2014.zip # unzip dataset"
      ],
      "metadata": {
        "id": "4Riu_d0bN7JO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b631c581-b9d9-42f1-852f-4d5e4b17bded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-10 16:17:57--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.33.169\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.33.169|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252872794 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2014.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.16M  70.8MB/s    in 3.4s    \n",
            "\n",
            "2022-07-10 16:18:00 (70.8 MB/s) - ‘annotations_trainval2014.zip’ saved [252872794/252872794]\n",
            "\n",
            "Archive:  annotations_trainval2014.zip\n",
            "  inflating: annotations/instances_train2014.json  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "from tqdm.notebook import tqdm\n",
        "# Load Json File with annotations\n",
        "with open(\"/content/annotations/instances_train2014.json\", \"rb\") as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "AYgBkF5pONFJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "32262851-07f4-43b4-9097-bfb1025aba9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-87eed39f9755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load Json File with annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/annotations/instances_train2014.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 286982145 (char 286982144)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_sublist(list1, list2):\n",
        "    l1 = list1.copy()\n",
        "    l2 = list2.copy()\n",
        "    for l in l1:\n",
        "        if l in l2:\n",
        "            l2.remove(l)\n",
        "        else:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "class COCO:\n",
        "    \n",
        "    def __init__(self, json_data):\n",
        "        self.json_data = json_data\n",
        "        self.categories = {}\n",
        "        self.coco = {}\n",
        "        for im in self.json_data[\"images\"]:\n",
        "            self.coco[im[\"id\"]] = {\"url\": im[\"flickr_url\"]} # αρχικά αποθηκευούμε για κάθε εικόνα το url της ώστε να μπορέσουμε να το εκτυπώσουμε\n",
        "    \n",
        "        for cat in self.json_data[\"categories\"]:\n",
        "            self.categories[cat[\"id\"]] = {\"name\": cat[\"name\"], \"supercategory\": cat[\"supercategory\"]} \n",
        "\n",
        "        anns_per_image = {}\n",
        "        print (\"Loading Coco Metadata\")\n",
        "        for ann in tqdm(self.json_data[\"annotations\"]):\n",
        "            if ann[\"image_id\"] not in anns_per_image:\n",
        "                anns_per_image[ann[\"image_id\"]] = {\"label_ids\": [ann[\"category_id\"]], \"label_texts\": [self.categories[ann[\"category_id\"]][\"name\"]]}\n",
        "            else:\n",
        "                anns_per_image[ann[\"image_id\"]][\"label_ids\"].append(ann[\"category_id\"])\n",
        "                anns_per_image[ann[\"image_id\"]][\"label_texts\"].append(self.categories[ann[\"category_id\"]][\"name\"])\n",
        "\n",
        "\n",
        "        # ενώνουμε τις κατηγορίες με το dict των εικόνων \n",
        "        for im_id in list(self.coco):\n",
        "            if im_id in anns_per_image:\n",
        "                self.coco[im_id][\"label_ids\"] = anns_per_image[im_id][\"label_ids\"]\n",
        "                self.coco[im_id][\"label_texts\"] = anns_per_image[im_id][\"label_texts\"]\n",
        "            else:\n",
        "                self.coco.pop(im_id, None) # αν δεν έχουμε annotations σβήνουμε το key αυτό \n",
        "\n",
        "\n",
        "\n",
        "    def prune_dataset(self, labels):\n",
        "        image_ids = list(self.coco.keys())\n",
        "        for image_id in image_ids:\n",
        "            if not is_sublist(labels, self.coco[image_id][\"label_texts\"]):\n",
        "                self.coco.pop(image_id, None)\n",
        "coco = COCO(data)\n",
        "\n",
        "\n",
        "print (f\"COCO keys: {coco.coco[list(coco.coco.keys())[0]].keys()}\")"
      ],
      "metadata": {
        "id": "B0BiXB34OkzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f\"Size of dataset before Pruning: {len(coco.coco)}\")\n",
        "coco.prune_dataset([\"chair\"])\n",
        "print (f\"Size of dataset after Pruning: {len(coco.coco)}\")"
      ],
      "metadata": {
        "id": "rmVUitoBQoZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(coco.coco)\n"
      ],
      "metadata": {
        "id": "BN5NWegrnRq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Places Predictor \n",
        "\n",
        "\n",
        "Παρακάτω σας δίνεται μια κλάση για η όποια υλοποιεί τον classifier που δόθηκε μαζί με την [δημοσιευση](http://places2.csail.mit.edu/) του Places Dataset από το MIT. Στην παρούσα εργασία καλείστε να τρέξετε τον ταξινομητή αυτό για τις εικόνες που επιλέξατε από το coco και με βάση τα prediction τους να προσπαθήσετε να εξηγήσετε την λειτουργία του ταξινομητή.  Η κλάση αυτή περιέχει μια μέθοδο `classify` η όποια δέχεται στην είσοδο ένα url και επιστρέφει τα 5 πρώτα prediction του classifier μαζί με τις αντίστοιχες πιθανότητες. \n",
        "\n",
        "Τέλος σας δίνεται και μια συνάρτηση ```read_image_from_url```  για το διάβασμα εικόνων από urls, ώστε να μπορείτε να τυπώνετε εικόνες στο περιβάλλον του notebook. "
      ],
      "metadata": {
        "id": "X_crl450S84K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "\n",
        "def read_image_from_url(img_url):\n",
        "    img = io.imread(img_url)\n",
        "    img = Image.fromarray(img)\n",
        "    return img"
      ],
      "metadata": {
        "id": "KhCEeERvMVqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY5kMljEMCTw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable as V\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms as trn\n",
        "from torch.nn import functional as F\n",
        "import os\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class Classifier:\n",
        "\n",
        "    def __init__(self, arch):\n",
        "        # th architecture to use\n",
        "        self.arch = arch\n",
        "\n",
        "        # load the pre-trained weights\n",
        "        self.model_file = '%s_places365.pth.tar' % self.arch\n",
        "        if not os.access(self.model_file, os.W_OK):\n",
        "            weight_url = 'http://places2.csail.mit.edu/models_places365/' + self.model_file\n",
        "            os.system('wget ' + weight_url)\n",
        "\n",
        "        self.model = models.__dict__[arch](num_classes=365)\n",
        "        checkpoint = torch.load(self.model_file, map_location=lambda storage, loc: storage)\n",
        "        state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
        "        self.model.load_state_dict(state_dict)\n",
        "        self.model.eval()\n",
        "\n",
        "\n",
        "        # load the image transformer\n",
        "        self.centre_crop = trn.Compose([\n",
        "                trn.Resize((256,256)),\n",
        "                trn.CenterCrop(224),\n",
        "                trn.ToTensor(),\n",
        "                trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # load the class label\n",
        "        file_name = 'categories_places365.txt'\n",
        "        if not os.access(file_name, os.W_OK):\n",
        "            synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
        "            os.system('wget ' + synset_url)\n",
        "        \n",
        "        self.classes = list()\n",
        "        with open(file_name) as class_file:\n",
        "            for line in class_file:\n",
        "                self.classes.append(line.strip().split(' ')[0][3:])\n",
        "        self.classes = tuple(self.classes)\n",
        "\n",
        "\n",
        "    # load the test image\n",
        "    def classify(self, img_url):\n",
        "      img = io.imread(img_url)\n",
        "      img = Image.fromarray(img)\n",
        "      input_img = V(self.centre_crop(img).unsqueeze(0))\n",
        "\n",
        "      # forward pass\n",
        "      logit = self.model.forward(input_img)\n",
        "      h_x = F.softmax(logit, 1).data.squeeze()\n",
        "      probs, idx = h_x.sort(0, True)\n",
        "      # output the prediction\n",
        "      preds = []\n",
        "      for i in range(0, 5):\n",
        "          preds.append([self.classes[idx[i]], float(probs[i])])\n",
        "      return preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = Classifier(\"resnet18\")"
      ],
      "metadata": {
        "id": "-mmD47GgMR7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://farm5.staticflickr.com/4141/4909108695_62224087a9_z.jpg\"\n",
        "print (f\"Image url: {image_url}\")\n",
        "image = read_image_from_url(image_url)\n",
        "plt.imshow(image)\n",
        "\n",
        "print (\"Predictions\")\n",
        "predictor.classify(image_url)"
      ],
      "metadata": {
        "id": "kEOLm2JEM0RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Γνώση και wordnet"
      ],
      "metadata": {
        "id": "JFiWlIX2BO7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το [owlready2](https://owlready2.readthedocs.io/en/v0.37/) είναι μια βιβλιοθήκη της python για τον χειρισμό και τη δημιουργία owl αρχείων."
      ],
      "metadata": {
        "id": "I-jwookUE46g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install owlready2"
      ],
      "metadata": {
        "id": "QPvTRFFIBSXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To [NLTK](https://www.nltk.org/) είναι βιβλιοθήκη για την επεξεργασία φυσικής γλώσσας. Εμείς θα το χρησιμοποιήσουμε για να συνδέσουμε τα ονόματα των αντικειμένων με synsets του [wordnet](https://www.nltk.org/howto/wordnet.html)"
      ],
      "metadata": {
        "id": "VKKabPl4FHF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from owlready2 import *\n",
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "13WTWDVnBYFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Δημιουργία Γνώσης"
      ],
      "metadata": {
        "id": "yJmt4sdHCrUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onto = get_ontology('http://myontology/')\n",
        "## ids των 100 πρώτων εικόνων\n",
        "ids = [k for k in coco.coco][:100]\n",
        "\n",
        "with onto:\n",
        "\n",
        "  ## Ορισμός εννοιών για εικόνες και αντικείμενα\n",
        "  class Image(Thing):\n",
        "    namespace=onto\n",
        "    pass\n",
        "\n",
        "  class DepictedObject(Thing):\n",
        "    namespace=onto\n",
        "    pass\n",
        "\n",
        "  ## Ορισμός ρόλου \"hasObject\" (ποιες εικόνες περιέχουν ποια αντικείμενα)\n",
        "  class hasObject(Image>>DepictedObject):\n",
        "    namespace=onto\n",
        "    pass\n",
        "\n",
        "  ## Για κάθε εικόνα\n",
        "  for im_id in ids:\n",
        "    ## Δημιουργία individual τύπου \"Image\"\n",
        "    im = onto['Image'](str(im_id))\n",
        "\n",
        "    ## Για κάθε αντικείμενο στην εικόνα:\n",
        "    for obj_name in coco.coco[im_id]['label_texts']:\n",
        "      \n",
        "\n",
        "      ## Εύρεση πρώτου synset στο wordnet\n",
        "      synsets = wn.synsets(obj_name)\n",
        "\n",
        "      if len(synsets)<1:\n",
        "        continue\n",
        "      \n",
        "      ## Δημιουργία individual τύπου \"Object\"\n",
        "      obj = onto['DepictedObject']()\n",
        "\n",
        "      ## Σύνδεση της εικόνας με το αντικείμενο μέσω του ρόλου hasObject\n",
        "      im.hasObject.append(obj)\n",
        "\n",
        "      synset = wn.synsets(obj_name)[0].name()\n",
        "      \n",
        "      ## Αν υπάρχει η αντίστοιχη έννοια στη γνώση\n",
        "      if onto[synset] in onto.classes():\n",
        "        ## Ορίζουμε το αντικείμενο obj ως τύπου \"synset\"\n",
        "        obj.is_a.append(onto[synset])\n",
        "        \n",
        "\n",
        "      ## Αν δεν υπάρχει η αντίστοιχη έννοια στη γνώση, την ορίζουμε, μαζί με τις υπερέννοιές της\n",
        "      else:\n",
        "        ## Εύρεση υπερώνυμων\n",
        "        hyper = lambda s:s.hypernyms()\n",
        "        hypers = [s.name() for s in list(wn.synset(synset).closure(hyper))]\n",
        "        hypers = reversed(hypers)\n",
        "\n",
        "        ## Ορισμός ιεραρχίας εννοιών\n",
        "        father = Thing\n",
        "        for h in hypers:\n",
        "          if onto[h] not in onto.classes():\n",
        "            with onto:\n",
        "              cl = types.new_class(h,(father,))\n",
        "          father = onto[h]\n",
        "        if onto[synset] not in onto.classes():\n",
        "          with onto:\n",
        "            cl = types.new_class(synset,(father,))\n",
        "        ## Ορίζουμε το αντικείμενο obj ως τύπου \"synset\"\n",
        "        with onto:\n",
        "          obj.is_a.append(onto[synset])\n",
        "        \n",
        "  ## Αποθηκεύουμε την οντολογία\n",
        "  onto.save('myonto.nt',format='ntriples')\n"
      ],
      "metadata": {
        "id": "cWabDCcNCJP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ερωτήματα στη Γνώση (GraphDB)\n",
        "\n",
        "Κατεβάζουμε το [GraphDB](https://www.ontotext.com/products/graphdb/graphdb-free/)\n",
        "\n",
        "Setup -> Repositories -> Create new repository -> GraphDB Free\n",
        "\n",
        "Ruleset -> OWL 2 RL (optimized) -> Create\n",
        "\n",
        "Connect to repository\n",
        "\n",
        "(αριστερά) Import -> Upload RDF files -> επιλέγετε το αρχείο της γνώσης (εδώ myonto.nt) -> import -> import\n",
        "\n",
        "(αριστερά) SPARQL. Μπορούμε να ζητήσουμε πχ όλες τις εικόνες που περιέχουν καρέκλες\n",
        "\n",
        "```\n",
        "prefix my:<http://myontology/>\n",
        "select ?image where { \n",
        "\t?image my:hasObject ?o .\n",
        "    ?o a my:chair.n.01.\n",
        "}\n",
        "```\n",
        "\n",
        "Επειδή έχει τρέξει ο reasoner του GraphDB, \"ξέρει\" (από το wordnet) πως όλες οι καρέκλες (chair.n.01) είναι καθίσματα (seat.n.03). οπότε μπορούμε να απαντήσουμε και το ερώτημα\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prefix my:<http://myontology/>\n",
        "select ?image where { \n",
        "\t?image my:hasObject ?o .\n",
        "    ?o a my:seat.n.03.\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "Μετά μπορούμε να κατεβάσουμε τα αποτελέσματα (Download as) σε ό,τι μορφή θέλουμε.\n",
        "\n",
        "Γενικά μπορούμε να κάνουμε πολύ σύνθετα SPARQL ερωτήματα, για τα οποία θα βρείτε πολύ υλικό online.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ODtw3JZCLhUD"
      }
    }
  ]
}