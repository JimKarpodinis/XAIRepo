@Article{Turing,
    author = {TURING, A. M.},
    title = "{I.—COMPUTING MACHINERY AND INTELLIGENCE}",
    journal = {Mind},
    volume = {LIX},
    number = {236},
    pages = {433-460},
    year = {1950},
    month = {10},
    issn = {0026-4423},
    doi = {10.1093/mind/LIX.236.433},
    url = {https://doi.org/10.1093/mind/LIX.236.433},
    eprint = {https://academic.oup.com/mind/article-pdf/LIX/236/433/30123314/lix-236-433.pdf},
}

@Article{quinlan,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Quinlan, J. R.},
  biburl = {https://www.bibsonomy.org/bibtex/24b1ef1c16c39d56f0f132c191870d776/schaul},
  citeulike-article-id = {2378698},
  description = {idsia},
  interhash = {3fe7356363a918dd24aeba82ba71d75a},
  intrahash = {4b1ef1c16c39d56f0f132c191870d776},
  journal = {Machine Learning},
  keywords = {nn},
  pages = {81--106},
  priority = {2},
  timestamp = {2008-02-26T12:02:56.000+0100},
  title = {Induction of Decision Trees},
  volume = 1,
  year = 1986
}

@Article{rosenblatt,
  added-at = {2017-07-19T15:29:59.000+0200},
  author = {Rosenblatt, F.},
  biburl = {https://www.bibsonomy.org/bibtex/214ee8da21c66cd4d00d7ab6eca2d96a9/andreashdez},
  citeulike-article-id = {13697582},
  citeulike-linkout-0 = {http://dx.doi.org/10.1037/h0042519},
  doi = {10.1037/h0042519},
  interhash = {dc0cef9dc06033a04f525efdcde7a660},
  intrahash = {14ee8da21c66cd4d00d7ab6eca2d96a9},
  issn = {0033-295X},
  journal = {Psychological Review},
  keywords = {imported},
  number = 6,
  pages = {386--408},
  posted-at = {2016-05-02 20:23:36},
  priority = {2},
  timestamp = {2017-07-19T15:31:02.000+0200},
  title = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
  url = {http://dx.doi.org/10.1037/h0042519},
  volume = 65,
  year = 1958
}

@article{symbols,
  number = 3,
  pages = {113-126},
  publisher = {ACM},
  timestamp = {2010-07-07T17:03:26.000+0200},
  title = {Computer science as empirical inquiry: symbols and search},
  url = {http://doi.acm.org/10.1145/1283920.1283930},
  volume = 19,
  year = 1976
}

@book{descriptionlogic,
author = {Baader, Franz and Calvanese, Diego and Mcguinness, Deborah and Nardi, Daniele and Patel-Schneider, Peter},
year = {2007},
month = {01},
pages = {},
title = {The Description Logic Handbook: Theory, Implementation, and Applications}
}

@Article{Deng,
  title={Deep Learning: Methods and Applications},
  author={Li Deng and Dong Yu},
  journal={Found. Trends Signal Process.},
  year={2014},
  volume={7},
  pages={197-387}
}

@article{xai,
title = {Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
journal = {Information Fusion},
volume = {58},
pages = {82-115},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2019.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
author = {Alejandro (Barredo Arrieta) and Natalia Díaz-Rodríguez and Javier (Del Ser) and Adrien Bennetot and Siham Tabik and Alberto Barbado and Salvador Garcia and Sergio Gil-Lopez and Daniel Molina and Richard Benjamins and Raja Chatila and Francisco Herrera},
keywords = {Explainable Artificial Intelligence, Machine Learning, Deep Learning, Data Fusion, Interpretability, Comprehensibility, Transparency, Privacy, Fairness, Accountability, Responsible Artificial Intelligence},
abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.}
}

@misc{coco,
  added-at = {2020-06-07T20:25:18.000+0200},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  biburl = {https://www.bibsonomy.org/bibtex/2f4ab9f41677ee189a8cbc5a92cc0dc74/jan.hofmann1},
  description = {Microsoft COCO: Common Objects in Context},
  interhash = {a3a26c6fe173264a6b812e3b7b4119bd},
  intrahash = {f4ab9f41677ee189a8cbc5a92cc0dc74},
  keywords = {thema:pyramid_scene_parsing},
  note = {cite arxiv:1405.0312Comment: 1) updated annotation pipeline description and figures; 2) added new  section describing datasets splits; 3) updated author list},
  timestamp = {2020-06-07T20:25:18.000+0200},
  title = {Microsoft COCO: Common Objects in Context},
  url = {http://arxiv.org/abs/1405.0312},
  year = 2014
}

@article{places,
  title={Places: A 10 Million Image Database for Scene Recognition},
  author={Bolei Zhou and {\`A}gata Lapedriza and Aditya Khosla and Aude Oliva and Antonio Torralba},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2018},
  volume={40},
  pages={1452-1464}
}

@InProceedings{resnet18,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{owlready2,
author = {Lamy, Jean-Baptiste},
year = {2017},
month = {08},
pages = {},
title = {Owlready: Ontology-oriented programming in Python with automatic classification and high level constructs for biomedical ontologies},
volume = {80},
journal = {Artificial Intelligence in Medicine},
doi = {10.1016/j.artmed.2017.07.002}
}
